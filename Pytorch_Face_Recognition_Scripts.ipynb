{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMG8KGcfBgFZ4ledVclN30P",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Adityaasati/PyTorch-Face-Recognition/blob/main/Pytorch_Face_Recognition_Scripts.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "qgiwH4jS82iD"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.makedirs(\"going_modular\", exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import zipfile\n",
        "import os\n",
        "from pathlib import Path\n",
        "import random\n",
        "import shutil\n",
        "\n",
        "# Define paths\n",
        "data_path = Path(\"data/\")\n",
        "image_path = data_path / \"celebrity_face_image_dataset\"\n",
        "\n",
        "\n",
        "# Check if the directory exists, otherwise create it\n",
        "if image_path.is_dir():\n",
        "    print(f\"{image_path} directory already exists... skipping download\")\n",
        "else:\n",
        "    print(f\"{image_path} does not exist, creating one...\")\n",
        "    image_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Download dataset\n",
        "dataset_url = \"https://github.com/Adityaasati/PyTorch-Face-Recognition/raw/refs/heads/main/celebrity_face_image_dataset.zip\"\n",
        "with open(data_path / \"celebrity_face_image_dataset.zip\", \"wb\") as f:\n",
        "    request = requests.get(dataset_url)\n",
        "    print(\"Downloading Celebrities Face Image data...\")\n",
        "    f.write(request.content)\n",
        "\n",
        "# Unzip the downloaded file\n",
        "with zipfile.ZipFile(data_path / \"celebrity_face_image_dataset.zip\", \"r\") as zip_ref:\n",
        "    print(\"Unzipping Celebrities Face Image data...\")\n",
        "    zip_ref.extractall(image_path)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p0vVACtM9BUd",
        "outputId": "f18d04b1-b55a-4dfe-d958-a9d3239b7a77"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data/celebrity_face_image_dataset directory already exists... skipping download\n",
            "Downloading Celebrities Face Image data...\n",
            "Unzipping Celebrities Face Image data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = image_path/\"celebrity_face_image_dataset\"\n",
        "train_dir = image_path/\"train\"\n",
        "test_dir = image_path/\"test\""
      ],
      "metadata": {
        "id": "tmXDelMe9ZZp"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile going_modular/Customs.py\n",
        "\n",
        "import random\n",
        "from PIL import Image\n",
        "from typing import Tuple, Dict, List\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "from pathlib import Path\n",
        "import os\n",
        "import torch\n",
        "\n",
        "data_path = Path(\"data/\")\n",
        "image_path = data_path / \"celebrity_face_image_dataset\"/\"celebrity_face_image_dataset\"\n",
        "train_dir = image_path/\"train\"\n",
        "test_dir = image_path/\"test\"\n",
        "target_directory = train_dir\n",
        "\n",
        "class_names = sorted([entry.name for entry in os.scandir(target_directory)])\n",
        "\n",
        "def class_and_idx(target_directory):\n",
        "  class_names = sorted(entry.name for entry in os.scandir(target_directory) if entry.is_dir())\n",
        "\n",
        "  class_idx = {class_name: i for i,class_name in enumerate(class_names)}\n",
        "\n",
        "  return class_names,class_idx\n",
        "\n",
        "class ImageFolderCustom(Dataset):\n",
        "  def __init__(self, targ_dir:str, transform=None):\n",
        "    self.paths = list(Path(targ_dir).glob(\"*/*.jpg\"))\n",
        "    self.transform=transform\n",
        "    self.classes, self.class_to_idx = class_and_idx(targ_dir)\n",
        "    print(self.class_to_idx,\"self.class_to_idx\")\n",
        "\n",
        "\n",
        "\n",
        "  def load_image(self, indx:int) -> Image:\n",
        "    image_path = self.paths[indx]\n",
        "    return Image.open(image_path)\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.paths)\n",
        "\n",
        "  def __getitem__(self, index:int) ->Tuple[torch.Tensor, int]:\n",
        "    img = self.load_image(index)\n",
        "    class_name = self.paths[index].parent.name\n",
        "    class_idx = self.class_to_idx[class_name]\n",
        "\n",
        "    if self.transform:\n",
        "      return self.transform(img), class_idx\n",
        "    else:\n",
        "      return img, class_idx\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zjD1f68p9m29",
        "outputId": "0b4fb3f9-9411-44d3-b834-5ef5a22dc999"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting going_modular/Customs.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile going_modular/data_setup.py\n",
        "\n",
        "import os\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "import Customs\n",
        "\n",
        "\n",
        "NUM_WORKERS = os.cpu_count()\n",
        "\n",
        "\n",
        "\n",
        "def create_dataloaders(\n",
        "    train_dir: str,\n",
        "    test_dir: str,\n",
        "    transform: transforms.Compose,\n",
        "    batch_size: int,\n",
        "    num_workers: int=NUM_WORKERS\n",
        "):\n",
        "  train_data = Customs.ImageFolderCustom(train_dir, transform=transform)\n",
        "  test_data = Customs.ImageFolderCustom(test_dir, transform=transform)\n",
        "\n",
        "  # Get class names\n",
        "  class_names = train_data.classes\n",
        "\n",
        "  # Turn images into data loaders\n",
        "  train_custom_dataloader = DataLoader(\n",
        "      train_data,\n",
        "      batch_size=batch_size,\n",
        "      shuffle=True,\n",
        "      num_workers=num_workers,\n",
        "      pin_memory=True,\n",
        "  )\n",
        "  test_custom_dataloader = DataLoader(\n",
        "      test_data,\n",
        "      batch_size=batch_size,\n",
        "      shuffle=False,\n",
        "      num_workers=num_workers,\n",
        "      pin_memory=True,\n",
        "  )\n",
        "\n",
        "  return train_custom_dataloader, test_custom_dataloader, class_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sXBBokUk-VxN",
        "outputId": "e5942930-8caa-4b3b-c2fb-85206ca1afa8"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting going_modular/data_setup.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile going_modular/model_builder.py\n",
        "\n",
        "from torch import nn\n",
        "class TinyVGG(nn.Module):\n",
        "  def __init__(self,\n",
        "               input_shape: int,\n",
        "               hidden_units:int,\n",
        "               output_shape:int):\n",
        "    super().__init__()\n",
        "    self.conv_block_1 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=input_shape,out_channels=hidden_units,kernel_size=3,stride=1,padding=0),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(in_channels=hidden_units,out_channels=hidden_units,kernel_size=3,stride=1,padding=0),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2,stride=2)\n",
        "    )\n",
        "    self.conv_block_2 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=hidden_units,out_channels=hidden_units,kernel_size=3,stride=1,padding=0),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(in_channels=hidden_units,out_channels=hidden_units,kernel_size=3,stride=1,padding=0),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2,stride=2)\n",
        "    )\n",
        "    self.classifier = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(in_features=hidden_units*29*29,out_features=output_shape)\n",
        "    )\n",
        "\n",
        "\n",
        "  def forward(self,x):\n",
        "    return self.classifier(self.conv_block_2(self.conv_block_1(x)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pMinKnSu-3Pm",
        "outputId": "26c70664-6925-4504-a068-c5ab6816a62f"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting going_modular/model_builder.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "from going_modular import model_builder\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Instantiate an instance of the model from the \"model_builder.py\" script\n",
        "torch.manual_seed(42)\n",
        "model_1 = model_builder.TinyVGG(input_shape=3, # number of color channels (3 for RGB)\n",
        "                                hidden_units=10,\n",
        "                                output_shape=len(class_names)).to(device)\n",
        "model_1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4lJambo8-5jF",
        "outputId": "06edd9c1-517c-4de4-fee3-ebcb3ccb587b"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TinyVGG(\n",
              "  (conv_block_1): Sequential(\n",
              "    (0): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (3): ReLU()\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (conv_block_2): Sequential(\n",
              "    (0): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (3): ReLU()\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (classifier): Sequential(\n",
              "    (0): Flatten(start_dim=1, end_dim=-1)\n",
              "    (1): Linear(in_features=8410, out_features=5, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile going_modular/engine.py\n",
        "from tqdm.auto import tqdm\n",
        "from torch import nn\n",
        "import torch\n",
        "from typing import Tuple, Dict, List\n",
        "\n",
        "\n",
        "def train_fn(model:torch.nn.Module,\n",
        "             dataloader:torch.utils.data.DataLoader,\n",
        "             loss_fn:torch.nn.Module,\n",
        "             optimizer:torch.optim.Optimizer,\n",
        "             device: torch.device) -> Tuple[float, float]:\n",
        "\n",
        "  model.train()\n",
        "\n",
        "  train_loss, train_acc =0,0\n",
        "\n",
        "\n",
        "  for batch, (X,y) in enumerate(dataloader):\n",
        "\n",
        "    X,y = X.to(device), y.to(device)\n",
        "\n",
        "    y_pred = model(X)\n",
        "\n",
        "    loss = loss_fn(y_pred, y)\n",
        "    train_loss+=loss.item()\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    y_pred_class = torch.argmax(torch.softmax(y_pred, dim=1), dim=1)\n",
        "    train_acc += (y_pred_class == y).sum().item()/len(y_pred)\n",
        "\n",
        "  train_loss = train_loss/len(dataloader)\n",
        "  train_acc = train_acc/len(dataloader)\n",
        "  return train_loss,train_acc\n",
        "\n",
        "def test_fn(model:torch.nn.Module,\n",
        "            dataloader: torch.utils.data.DataLoader,\n",
        "            loss_fn:torch.nn.Module,\n",
        "            device: torch.device) -> Tuple[float, float]:\n",
        "\n",
        "  model.eval()\n",
        "  test_loss, test_acc=0,0\n",
        "\n",
        "  with torch.inference_mode():\n",
        "    for batch, (X,y) in enumerate(dataloader):\n",
        "      X,y = X.to(device),y.to(device)\n",
        "      test_pred = model(X)\n",
        "\n",
        "      loss = loss_fn(test_pred,y)\n",
        "      test_loss+=loss.item()\n",
        "\n",
        "      test_labels = test_pred.argmax(dim=1)\n",
        "      test_acc += (test_labels == y).sum().item()/len(test_pred)\n",
        "\n",
        "  test_loss = test_loss/len(dataloader)\n",
        "  test_acc = test_acc/len(dataloader)\n",
        "\n",
        "  return test_loss, test_acc\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def train_and_test(model: torch.nn.Module,\n",
        "          train_dataloader: torch.utils.data.DataLoader,\n",
        "          test_dataloader: torch.utils.data.DataLoader,\n",
        "          optimizer: torch.optim.Optimizer,\n",
        "          loss_fn: torch.nn.Module,\n",
        "          epochs: int,\n",
        "          device: torch.device) -> Dict[str, List[float]]:\n",
        "\n",
        "  results = {\"train_acc\":[],\n",
        "             \"train_loss\":[],\n",
        "             \"test_acc\":[],\n",
        "             \"test_loss\":[]\n",
        "             }\n",
        "  for epoch in tqdm(range(epochs)):\n",
        "    train_loss, train_acc  = train_fn(model=model,\n",
        "                                    dataloader=train_dataloader,\n",
        "                                    loss_fn=loss_fn,\n",
        "                                    optimizer=optimizer,\n",
        "                                      device=device)\n",
        "    test_loss, test_acc  = test_fn(model=model,\n",
        "                                    dataloader=test_dataloader,\n",
        "                                    loss_fn=loss_fn,\n",
        "                                    device=device)\n",
        "    print(f\"Epoch: {epoch} | Train Loss: {train_loss} | Train acc: {train_acc} | Test Loss: {test_loss} | Test acc: {test_acc}\")\n",
        "    results['train_acc'].append(train_acc)\n",
        "    results['train_loss'].append(train_loss)\n",
        "    results['test_acc'].append(test_acc)\n",
        "    results['test_loss'].append(test_loss)\n",
        "\n",
        "  return results\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9s5M4diW_KC9",
        "outputId": "6008b1d5-2e7f-4261-a875-4162e3a3067b"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting going_modular/engine.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile going_modular/utils.py\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "import torch\n",
        "\n",
        "def save_model(model: torch.nn.Module,\n",
        "               target_dir: str,\n",
        "               model_name: str):\n",
        "    # Create target directory\n",
        "    target_dir_path = Path(target_dir)\n",
        "    target_dir_path.mkdir(parents=True,\n",
        "                        exist_ok=True)\n",
        "\n",
        "    # Create model save path\n",
        "    assert model_name.endswith(\".pth\") or model_name.endswith(\".pt\"), \"model_name should end with '.pt' or '.pth'\"\n",
        "    model_save_path = target_dir_path / model_name\n",
        "\n",
        "    # Save the model state_dict()\n",
        "    print(f\"[INFO] Saving model to: {model_save_path}\")\n",
        "    torch.save(obj=model.state_dict(),\n",
        "             f=model_save_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kQRUmzoZ_Neq",
        "outputId": "13b5954e-41d8-4c55-ffe5-a60299f17e1d"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting going_modular/utils.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " ### This will allow us to run all of the functions we've written with a single line of code on the command line:\n",
        "\n",
        "python going_modular/train.py\n",
        "\n",
        "Or if we're running it in a notebook:\n",
        "\n",
        "!python going_modular/train.py"
      ],
      "metadata": {
        "id": "N3eLCmoD_ZQG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile going_modular/train.py\n",
        "\n",
        "\n",
        "import os\n",
        "import torch\n",
        "from pathlib import Path\n",
        "from torchvision import transforms\n",
        "import data_setup, engine, model_builder, utils\n",
        "\n",
        "\n",
        "# Setup hyperparameters\n",
        "NUM_EPOCHS = 5\n",
        "BATCH_SIZE = 32\n",
        "HIDDEN_UNITS = 10\n",
        "LEARNING_RATE = 0.001\n",
        "\n",
        "# Setup directories\n",
        "# train_dir = \"data/pizza_steak_sushi/train\"\n",
        "# test_dir = \"data/pizza_steak_sushi/test\"\n",
        "data_path = Path(\"data/\")\n",
        "image_path = data_path / \"celebrity_face_image_dataset\"/ \"celebrity_face_image_dataset\"\n",
        "train_dir = image_path/\"train\"\n",
        "test_dir = image_path/\"test\"\n",
        "\n",
        "# Setup target device\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Create transforms\n",
        "data_transform = transforms.Compose([transforms.Resize(size=(128,128)),\n",
        "                                                       transforms.RandomHorizontalFlip(p=0.5),\n",
        "                                                       transforms.ToTensor()])\n",
        "\n",
        "# Create DataLoaders with help from data_setup.py\n",
        "train_dataloader, test_dataloader, class_names = data_setup.create_dataloaders(\n",
        "    train_dir=train_dir,\n",
        "    test_dir=test_dir,\n",
        "    transform=data_transform,\n",
        "    batch_size=BATCH_SIZE\n",
        ")\n",
        "\n",
        "# Create model with help from model_builder.py\n",
        "model = model_builder.TinyVGG(\n",
        "    input_shape=3,\n",
        "    hidden_units=HIDDEN_UNITS,\n",
        "    output_shape=len(class_names)\n",
        ").to(device)\n",
        "\n",
        "# Set loss and optimizer\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(),\n",
        "                             lr=LEARNING_RATE)\n",
        "\n",
        "print(device,\"device\")\n",
        "# Start training with help from engine.py\n",
        "engine.train_and_test(model=model,\n",
        "             train_dataloader=train_dataloader,\n",
        "             test_dataloader=test_dataloader,\n",
        "             loss_fn=loss_fn,\n",
        "             optimizer=optimizer,\n",
        "             epochs=NUM_EPOCHS,\n",
        "             device=device)\n",
        "\n",
        "# Save the model with help from utils.py\n",
        "utils.save_model(model=model,\n",
        "                 target_dir=\"models\",\n",
        "                 model_name=\"going_modular_script_mode_tinyvgg_model.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z5dTVOh6_hNB",
        "outputId": "57e5fb30-4741-4fa4-bc7e-992c8f3e04ae"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting going_modular/train.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python going_modular/train.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-iH15moDQYM",
        "outputId": "a74c7aae-6bd5-4a2e-94a6-8521e784e3c2"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Brad Pitt': 0, 'Johnny Depp': 1, 'Leonardo DiCaprio': 2, 'Tom Cruise': 3, 'Will Smith': 4} self.class_to_idx\n",
            "{'Brad Pitt': 0, 'Johnny Depp': 1, 'Leonardo DiCaprio': 2, 'Tom Cruise': 3, 'Will Smith': 4} self.class_to_idx\n",
            "cpu device\n",
            "  0% 0/5 [00:00<?, ?it/s]Epoch: 0 | Train Loss: 1.6346796567623432 | Train acc: 0.15865384615384615 | Test Loss: 1.5909542739391327 | Test acc: 0.375\n",
            " 20% 1/5 [00:08<00:35,  9.00s/it]Epoch: 1 | Train Loss: 1.612407244168795 | Train acc: 0.20432692307692307 | Test Loss: 1.59875950217247 | Test acc: 0.3359375\n",
            " 40% 2/5 [00:17<00:26,  8.71s/it]Epoch: 2 | Train Loss: 1.6062113963640654 | Train acc: 0.2283653846153846 | Test Loss: 1.5880542397499084 | Test acc: 0.1484375\n",
            " 60% 3/5 [00:25<00:16,  8.24s/it]Epoch: 3 | Train Loss: 1.6013263280575092 | Train acc: 0.21875 | Test Loss: 1.5955927968025208 | Test acc: 0.1640625\n",
            " 80% 4/5 [00:33<00:08,  8.40s/it]Epoch: 4 | Train Loss: 1.589718561906081 | Train acc: 0.2283653846153846 | Test Loss: 1.5923909842967987 | Test acc: 0.2265625\n",
            "100% 5/5 [00:41<00:00,  8.24s/it]\n",
            "[INFO] Saving model to: models/going_modular_script_mode_tinyvgg_model.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Xv_ZJJZxDZkX"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vem4dcU9JKK4"
      },
      "execution_count": 97,
      "outputs": []
    }
  ]
}